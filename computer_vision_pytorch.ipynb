{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRIHnYnXYfECSFu0CCOq4I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alton01/computer_vision_pytorch/blob/main/computer_vision_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oz2Tou-NTlTy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # where data is to be downloaded to\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # where data is to be downloaded to\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVFd1s1jgjib",
        "outputId": "69722cf5-713e-4efd-91ea-e3dc5d8d9689"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 14.3MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 269kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:00<00:00, 5.05MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 17.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHE6EaDhjNst",
        "outputId": "5b4da887-048f-4fee-c7ff-06aacd34f1f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image, label = train_data[0]\n",
        "print(f\"image shape: {image.shape}, label: {label}\")\n",
        "\n",
        "plt.imshow(image.squeeze())\n",
        "plt.title(label)"
      ],
      "metadata": {
        "id": "4LRqCwETl4g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#visualizing the data\n",
        "class_names = train_data.classes\n",
        "torch.manual_seed(42)\n",
        "fig = plt.figure(figsize=(9, 9)) #creates a square figure with both width and height set to 9 inches.\n",
        "rows, cols = 4, 4\n",
        "for i in range(1, rows * cols + 1):\n",
        "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
        "    img, label = train_data[random_idx]\n",
        "    fig.add_subplot(rows, cols, i)\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\") # we squeeze to avoid problems with matplotlib by removing any 1 extra dimension\n",
        "    plt.title(class_names[label], fontsize=14)\n",
        "    plt.axis(False)"
      ],
      "metadata": {
        "id": "tMYiEJA0oPS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader batchifies our data due to compute memory.\n",
        "# it also gives our neural network more chances to update its gradient per epoch. at 32 images per batch instead of 60,000 images.\n",
        "# our neural network updates its weight every 32 images thanks to the optimizer.\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDdn2Vv-sjhN",
        "outputId": "dd7b592d-246d-4750-d80a-b52105450d9c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7b9d75cada90>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7b9d75e29010>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQAO0XW6ypwq",
        "outputId": "0a358b1e-7f34-4be7-95d5-672c84b5de1f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1875, 313)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#structure of train_loader\n",
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "train_features_batch.shape, train_labels_batch.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLyak-FmzwnG",
        "outputId": "af21d369-8806-4ae2-e865-c616aeaee7ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show a sample\n",
        "torch.manual_seed(42)\n",
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.title(class_names[label], fontsize=14)\n",
        "plt.axis(False)"
      ],
      "metadata": {
        "id": "9pgLEGal0B-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flatten_model = nn.Flatten() # flattens a contiguous range of dims into a tensor/vector. For use with sequential()\n",
        "# condensing information down into a single vector space because we are also using a linear layer in the model\n",
        "#  which cant handle multi dimensional data so we condense it into a single vector as input.\n",
        "x = train_features_batch[0]\n",
        "\n",
        "output = flatten_model(x)\n",
        "print(f\"Shape before flattening: {x.shape}\")\n",
        "print(f\"Shape after flattening: {output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9c24eG42r3v",
        "outputId": "fa52ce55-9069-4de4-ed50-aaf84855e335"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape before flattening: torch.Size([1, 28, 28])\n",
            "Shape after flattening: torch.Size([1, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int):\n",
        "    super().__init__()\n",
        "    self.layer_stack = nn.Sequential(\n",
        "      nn.Flatten(),\n",
        "      nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
        "      nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_stack(x)\n"
      ],
      "metadata": {
        "id": "SCP5AfI1DV2D"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "model_0 = FashionMNISTModelV0(\n",
        "    input_shape=784,\n",
        "    hidden_units=10,\n",
        "    output_shape=len(class_names)\n",
        ").to(\"cpu\")\n",
        "\n",
        "model_0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXhjf2y4E2af",
        "outputId": "b9f65720-dbbb-48eb-bb9e-8b5544b32ab2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FashionMNISTModelV0(\n",
              "  (layer_stack): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
              "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "if Path(\"helper_functions.py\").is_file():\n",
        "  print(\"helper_functions.py already exists, skipping download...\")\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
        "  with open(\"helper_functions.py\", \"wb\") as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbFcoyrtJWLr",
        "outputId": "b612cdf9-a233-404e-c6c7-712bad4eaca5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading helper_functions.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function and optimizer\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)\n",
        "\n",
        "# Calculate accuracy (a classification metric)\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "xFtNzJlPF2Ip"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for timing our experiments\n",
        "\n",
        "from timeit import default_timer as timer # measures execution time of code\n",
        "\n",
        "def print_train_time(start: float,\n",
        "                     end: float,\n",
        "                     device: torch.device = None):\n",
        "    total_time = end - start\n",
        "    print(f\"Train time on {device}: {total_time:.3f} seconds\")\n",
        "    return total_time"
      ],
      "metadata": {
        "id": "D0R_HtOMK00x"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = timer()\n",
        "end_time = timer()\n",
        "print_train_time(start=start_time, end=end_time, device=\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11jBqNGBM6jr",
        "outputId": "9dcebbe3-91f7-47bb-996e-239bb37662cd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train time on cpu: 0.000 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.808199999217777e-05"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tqdm for progress bar\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_time_start_on_cpu = timer()\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "    print(f\"Epoch: {epoch}\\n---------\")\n",
        "\n",
        "    #Training\n",
        "    train_loss = 0\n",
        "    # Add a loop to loop through the training batches\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "        model_0.train()\n",
        "\n",
        "        y_pred = model_0(X)\n",
        "\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss\n",
        "\n",
        "        optimizer.zero_grad() # clears gradients of model's parameters otherwise gradients from previous batches would accumulate.\n",
        "\n",
        "        loss.backward() # calculates gradients of the loss with respect to the model's parameters\n",
        "\n",
        "        optimizer.step() # updates the model's parameters based on the calculated gradients\n",
        "\n",
        "        if batch % 400 == 0:\n",
        "          print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
        "\n",
        "    train_loss /= len(train_dataloader\n",
        "    )\n",
        "\n",
        "    # TESTING\n",
        "    test_loss, test_acc = 0, 0\n",
        "    model_0.eval()\n",
        "\n",
        "    with torch.inference_mode():\n",
        "      for X_test, y_test in test_dataloader:\n",
        "\n",
        "        test_pred = model_0(X_test) #output in logits\n",
        "\n",
        "        test_loss += loss_fn(test_pred, y_test)\n",
        "\n",
        "        test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1)) #use argmax to convert highest logit to label.\n",
        "\n",
        "      # calculate test loss average per batch\n",
        "      test_loss /= len(test_dataloader)\n",
        "\n",
        "      # calculate test accuracy average per batch\n",
        "      test_acc /= len(test_dataloader)\n",
        "\n",
        "\n",
        "    print(f\"\\n Train loss: {train_loss:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n",
        "\n",
        "train_time_end_on_cpu = timer()\n",
        "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu, end=train_time_end_on_cpu,\n",
        "                                            device=str(next(model_0.parameters()).device))"
      ],
      "metadata": {
        "id": "h3cnLeCAOIrj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}